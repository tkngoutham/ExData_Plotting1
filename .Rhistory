dat<-read.csv('/home/kushwanth/machinelearning/Assign1/lasso tutorial/Prostate.csv')
View(dat)
tdat<-dat[dat$train==TRUE,]
vdat<-dat[dat$train==FALSE,]
#center and scale all predictors - necessary for shrinkage methods
tdats<-data.frame(
lcavol  =(tdat$lcavol  -mean(tdat$lcavol ))/sd(tdat$lcavol ),
lweight =(tdat$lweight -mean(tdat$lweight))/sd(tdat$lweight),
age     =(tdat$age     -mean(tdat$age    ))/sd(tdat$age    ),
lbph    =(tdat$lbph    -mean(tdat$lbph   ))/sd(tdat$lbph   ),
svi     =(tdat$svi     -mean(tdat$svi    ))/sd(tdat$svi    ),
lcp     =(tdat$lcp     -mean(tdat$lcp    ))/sd(tdat$lcp    ),
gleason =(tdat$gleason -mean(tdat$gleason))/sd(tdat$gleason),
pgg45   =(tdat$pgg45   -mean(tdat$pgg45  ))/sd(tdat$pgg45  )
)
install.packages('lars')
lpsa    =tdat$lpsa
attach(tdats)
pairs(tdats)
cor(tdats)
plot(lcavol,lpsa,pch=16,main='Describe the association')
lcavolfit<-summary(lm(lpsa~lcavol))
plot(lcavol,lpsa,pch=16,main='Data plus estimated regression line')
abline(lcavolfit$coeff[1,1],lcavolfit$coeff[2,1],col='red',lwd=3)
plot(lcavol,lpsa,pch=16,main='Data plus estimated regression line?')
abline(lcavolfit$coeff[1,1],lcavolfit$coeff[2,1],col='red',lwd=3)
abline(a=-2,b=3,col='darkgreen',lwd=3)
plot(lcavol,lpsa,pch=16,main='Data plus estimated regression line?')
abline(lcavolfit$coeff[1,1],lcavolfit$coeff[2,1],col='red',lwd=3)
abline(a=1.2,b=1,col='darkblue',lwd=3)
par(mfrow=c(2,4))
plot(age,lpsa,pch=16,cex.lab=1.5)
abline(agefit$coeff[1,1],agefit$coeff[2,1],col='red',lwd=3)
plot(gleason,lpsa,pch=16,cex.lab=1.5)
gleasonfit<-summary(lm(lpsa~gleason))
abline(gleasonfit$coeff[1,1],gleasonfit$coeff[2,1],col='red',lwd=3)
plot(lbph,lpsa,pch=16,cex.lab=1.5)
lbphfit<-summary(lm(lpsa~lbph))
abline(lbphfit$coeff[1,1],lbphfit$coeff[2,1],col='red',lwd=3)
plot(lcavol,lpsa,pch=16,cex.lab=1.5)
lcavolfit<-summary(lm(lpsa~lcavol))
abline(lcavolfit$coeff[1,1],lcavolfit$coeff[2,1],col='red',lwd=3)
plot(lweight,lpsa,pch=16,cex.lab=1.5)
lweightfit<-summary(lm(lpsa~lweight))
abline(lweightfit$coeff[1,1],lweightfit$coeff[2,1],col='red',lwd=3)
plot(svi,lpsa,pch=16,cex.lab=1.5)
svifit<-summary(lm(lpsa~svi))
abline(svifit$coeff[1,1],svifit$coeff[2,1],col='red',lwd=3)
plot(lcp,lpsa,pch=16,cex.lab=1.5)
lcpfit<-summary(lm(lpsa~lcp))
abline(lcpfit$coeff[1,1],lcpfit$coeff[2,1],col='red',lwd=3)
plot(pgg45,lpsa,pch=16,cex.lab=1.5)
pgg45fit<-summary(lm(lpsa~pgg45))
abline(pgg45fit$coeff[1,1],pgg45fit$coeff[2,1],col='red',lwd=3)
OLS<-summary(lm(lpsa~.,data=tdats))
OLS
abline(lcavolfit$coeff[1,1],lcavolfit$coeff[2,1],col='red',lwd=3)
dat<-read.csv('/home/kushwanth/machinelearning/Assign1/lasso tutorial/Prostate.csv')
#Split data into a training and validation set
tdat<-dat[dat$train==TRUE,]
vdat<-dat[dat$train==FALSE,]
#center and scale all predictors - necessary for shrinkage methods
tdats<-data.frame(
lcavol  =(tdat$lcavol  -mean(tdat$lcavol ))/sd(tdat$lcavol ),
lweight =(tdat$lweight -mean(tdat$lweight))/sd(tdat$lweight),
age     =(tdat$age     -mean(tdat$age    ))/sd(tdat$age    ),
lbph    =(tdat$lbph    -mean(tdat$lbph   ))/sd(tdat$lbph   ),
svi     =(tdat$svi     -mean(tdat$svi    ))/sd(tdat$svi    ),
lcp     =(tdat$lcp     -mean(tdat$lcp    ))/sd(tdat$lcp    ),
gleason =(tdat$gleason -mean(tdat$gleason))/sd(tdat$gleason),
pgg45   =(tdat$pgg45   -mean(tdat$pgg45  ))/sd(tdat$pgg45  )
)
lpsa    =tdat$lpsa
#By default, refer to objects in tdat
attach(tdats)
#examine the correlation among the values in the data
pairs(tdats)
cor(tdats)
#Some basic regressions
#regrssion review code
plot(lcavol,lpsa,pch=16,main='Describe the association')
lcavolfit<-summary(lm(lpsa~lcavol))
plot(lcavol,lpsa,pch=16,main='Data plus estimated regression line')
abline(lcavolfit$coeff[1,1],lcavolfit$coeff[2,1],col='red',lwd=3)
plot(lcavol,lpsa,pch=16,main='Data plus estimated regression line?')
abline(lcavolfit$coeff[1,1],lcavolfit$coeff[2,1],col='red',lwd=3)
abline(a=-2,b=3,col='darkgreen',lwd=3)
plot(lcavol,lpsa,pch=16,main='Data plus estimated regression line?')
abline(lcavolfit$coeff[1,1],lcavolfit$coeff[2,1],col='red',lwd=3)
abline(a=1.2,b=1,col='darkblue',lwd=3)
#Bivariate relationship between lpsa (the outcome) and each predictor
par(mfrow=c(2,4))
plot(age,lpsa,pch=16,cex.lab=1.5)
agefit<-summary(lm(lpsa~age))
abline(agefit$coeff[1,1],agefit$coeff[2,1],col='red',lwd=3)
plot(gleason,lpsa,pch=16,cex.lab=1.5)
gleasonfit<-summary(lm(lpsa~gleason))
abline(gleasonfit$coeff[1,1],gleasonfit$coeff[2,1],col='red',lwd=3)
plot(lbph,lpsa,pch=16,cex.lab=1.5)
lbphfit<-summary(lm(lpsa~lbph))
abline(lbphfit$coeff[1,1],lbphfit$coeff[2,1],col='red',lwd=3)
plot(lcavol,lpsa,pch=16,cex.lab=1.5)
lcavolfit<-summary(lm(lpsa~lcavol))
abline(lcavolfit$coeff[1,1],lcavolfit$coeff[2,1],col='red',lwd=3)
plot(lweight,lpsa,pch=16,cex.lab=1.5)
lweightfit<-summary(lm(lpsa~lweight))
abline(lweightfit$coeff[1,1],lweightfit$coeff[2,1],col='red',lwd=3)
plot(svi,lpsa,pch=16,cex.lab=1.5)
svifit<-summary(lm(lpsa~svi))
abline(svifit$coeff[1,1],svifit$coeff[2,1],col='red',lwd=3)
plot(lcp,lpsa,pch=16,cex.lab=1.5)
lcpfit<-summary(lm(lpsa~lcp))
abline(lcpfit$coeff[1,1],lcpfit$coeff[2,1],col='red',lwd=3)
plot(pgg45,lpsa,pch=16,cex.lab=1.5)
pgg45fit<-summary(lm(lpsa~pgg45))
abline(pgg45fit$coeff[1,1],pgg45fit$coeff[2,1],col='red',lwd=3)
#Examine the ordinary least squares fit of the full model using multiple regression
OLS<-summary(lm(lpsa~.,data=tdats))
OLS
#############################################################
#####################Section 2 implement lasso###############
#############################################################
#Load the lars packagem, which can fit the lasso
library(lars)
?lars  #What does lars do?
#define a lasso-object
lasso<-lars(x=as.matrix(tdats),y=lpsa,type='lasso',trace=FALSE,normalize=TRUE,intercept=TRUE)
par(mfrow=c(1,1));plot(lasso)
lasso
coef(lasso) #look at lasso coefficients at each step
round(coef(lasso),3) #look at lasso coefficients at each step
train_url <- "http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv"
train <- read.csv(train_url)
# Import the testing set: test
test_url <- "http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv"
test <- read.csv(test_url)
prop.table(table(train$Sex,train$Survived))
table(train$Sex,train$Survived)
81/
(81+468)
81/(81+468)
81/(81+233)
81/(81+233+468+109)
table(train$Sex,train$Survived)
prop.table(table(train$Sex,train$Survived),margin=1)
81/(81+468)
81/(81+233)
prop.table(table(train$Sex),table(train$Survived))
prop.table(table(train$Sex,train$Survived))
prop.table(table(train$Sex,train$Survived),margin=2)
table(train$Sex,train$Survived)
81/(81+468)
str(train)
train$Child<-NA
train$Child[train$Age<18]<-1
train$Child[train$Age>=18]<-0
View(train)
table(train$Child)
train$Child<-NA
train$Child[train$Age<18]<-1
train$Child[train$Age>=18]<-0
train$Child[train$Age==NA]<-NA
table(train$Child)
str(train)
sum(train$Child==NA)
sum(train$Child=='NA')
sum(train$Child==1)
sum(train$Child)
train$Child
train$Child==1
is.na(train$Child)
sum(is.na(train$Child)==TRUE)
table(train$Child)
601+113+177
table(train$Child,train$Survived)
prop.table(table(train$Child,train$Survived),margin=1)
prop.table(table(train$Sex,train$Survived),margin=1)
str(train)
str(test)
test$Sex=="female"
library(rpart)
prop.table(table(train$Child,train$Survived),margin=1)
prop.table(table(train$Sex,train$Survived),margin=1)
my_tree <- rpart(Survived ~ Sex + Age,data = train,method ="class")
plot(my_tree)
text(my_tree)
plot(my_tree)
text(my_tree)
colnames(train)
my_tree_two <- rpart(Survived ~ Pclass+Sex+Age+SibSp+Parch+Fare+Embarked,data=train,method="class")
plot(my_tree_two)
text(my_tree_two)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
install.packages("rattle")
install.packages("RGtk2")
install.packages('RMySQL')
install.packages('DMwR')
update.packages()
head(algae)
library(DMwR)
head(algae)
ls
ls()
v <- c(4, 7, 23.5, 76.2, 80, "rrt")
length(v)
mode(v)
v <- c(4, 7, 23.5, 76.2, 80)
length(v)
mode(v)
k <- c(T, F, NA, TRUE)
mode(k)
u <- c(4, 6, NA, 2)
mode(u)
x <- vector()
length(x)
x[3]<-33
x
length(x)
x[10]
length(x)
x[5]<-4
length(x)
x
v1 <- c(4, 6, 8, 24)
v2 <- c(10, 2, 4)
v1 + v2
g <- c("f", "m", "m", "m", "f", "m", "f", "m", "f", "f")
factor((g))
factor(g)
g<-factor(g)
g
mode(g)
g
h<-factor(c(m,m,m,f,f))
h<-factor(c('m','m','m','f','f'))
h
g<-factor(g,h)
g<-c(g,h)
g
g
h
g <- c("f", "m", "m", "m", "f", "m", "f", "m", "f", "f")
table(g)
g <- c("f", "m", "m", "m", "f", "m", "f", "m", "f", "f","f")
table(g)
g <- c("f", "m", "m", "m", "f", "m", "f", "m", "f", "f")
a <- factor(c('adult','adult','juvenile','juvenile','adult','adult',
'adult','juvenile','adult','juvenile'))
table(a,g)
table(a,g)
t<-table(a,g)
t
margin.table(t,1)
margin.table(t,2)
prop.table(t)
prop.table(t,1)
prop.table(t,1)*100
seq(-10,10,1)
plot(seq(-10,10,1))
plot(seq(-10,10,2))
seq(from=1, to=-1,length=10)
seq(length = 10, from = -2, by = 0.2)
rep(1:3,3)
rep(1:2, each = 3)
rep(-2:1, each = 3)
gl(2, 5, labels = c("female", "male"))
rnorm(10)
sum(rnorm(10))/10
rnorm(10)
sum(rnorm(10))
sum(rnorm(100))
sum(rnorm(1000))
sum(rnorm(10000))
sum(rnorm(100000))
pH <- c(area1 = 4.5, area2 = 7, mud = 7.3, dam = 8.2, middle = 6.3)
mode(pH)
m <- c(45, 23, 66, 77, 33, 44, 56, 12, 78, 23)
dim(m)<-c(2,6)
dim(m)<-c(2,5)
m
dim(m)<-c(2,1,5)
m
library(DMwR)
data("GSPC")
rm(list=ls())
data("GSPC")
data(GSPC)
head(GSPC)
install.packages("zoo")
install.packages("xts")
install.packages("tseries")
x1 <- xts(rnorm(100), seq(as.POSIXct("2000-01-01"), len = 100,by = "day"))
x1 <- xts(rnorm(100), seq(as.POSIXct("2000-01-01"), len = 100,by = "day"))
library(xts)
x1 <- xts(rnorm(100), seq(as.POSIXct("2000-01-01"), len = 100,by = "day"))
head(x1)
head(x1)
round(rnorm(25),2)
round(rnorm(25),3)
matrix(round(rnorm(25),2),5,5)
paste(ts,1:5,sep='')
paste('ts',1:5,sep='')
paste('ts',1:5,sep=' ')
paste('ts',1:5,sep='_')
paste('ts',1:5,sep='-')
paste('ts',1:5,sep='*')
mts.vals<-matrix(round(rnorm(25),2),5,5)
colnames(mts.vals)<-paste('ts',1:5,sep='')
mts.vals
mts <- xts(mts.vals,as.POSIXct(c('2003-01-01','2003-01-04',
'2003-01-05','2003-01-06','2003-02-16')))
mts
mode(mts)
mts["2003-01",c("ts2","ts5")]
mts
mts.vals
index(mts)
time(mts)
coredata(mts)
install.packages("KernSmooth")
library(KernSmooth)
a<-(1,2,NA,4,5)
a<-C(1,2,NA,4,5)
a<-c(1,2,NA,4,5)
A
a
b<-c(NA,2,NA,4,5)
B
b
a
complete.cases(a,b)
complete.cases(b,a)
b<-c(NA,2,NA,4,NA)
complete.cases(b,a)
x<-4
class(x)
x<-c(4,TRUE)
class(x)
x <- c(1,3, 5); y <- c(3, 2, 10)
rbind(x,b)
rbind(x,y)
x <- list(2, "a", "b", TRUE)
x
x[[1]]
class(x[[1]])
x <- list(list(2,TRUE), "a", "b", TRUE)
X
X
x
x <- 1:4 ; y <- 2:3
x+y
x+y
x
y
x <- c(3, 5, 1, 10, 12, 6)
x
x[x<=5]<-0
x
x[x %in% 1:5]<-0
x <- c(3, 5, 1, 10, 12, 6)
x[x %in% 1:5]<-0
x
x[x<6]==0
x
x <- c(3, 5, 1, 10, 12, 6)
x[x<6]==0
dataset<-read.csv('/home/kushwanth/machinelearning/r_practice/DataScience_Specialization/R programming/hw1_data.csv')
colnames(datase\)
colnames(dataset)
dataset[1:2,]
nrows(dataset)
sizee(dataset)
size(dataset)
dims(dataset)
dimnames(dataset)
tail
tail(dataset,2)
dataset[47,]
dataset[47,]
sum(complete.cases(dataset[,1])==FALSE)
mean(complete.cases(dataset[,1]))
dataset[,1]
dataset['Ozone']
sum(complete.cases(dataset['Ozone'])==FALSE)
complete.cases(dataset['Ozone'])
dataset['Ozone'][complete.cases(dataset['Ozone'])]
(dataset['Ozone'])[complete.cases(dataset['Ozone'])]
temp<-dataset['Ozone']
temp
temp[complete.cases(dataset['Ozone'])]
temp[complete.cases(dataset['Ozone'])==TRUE]
temp(is.na())
temp[is.na()]
temp[is.na(temp)]
temp[!is.na(temp)]
mean(temp[!is.na(temp)])
mean(dataset['Ozone'][!is.na(dataset['Ozone'])])
dataset$Ozone
dataset[dataset$Ozone>31 & datset$Temp>90]
dataset[dataset$Ozone>31 & dataset$Temp>90]
colnames(dataset)
dataset$Temp
dataset$Ozone
dataset[dataset$Ozone>31 & dataset$Temp>90]
dataset(dataset$Ozone>31 & dataset$Temp>90)
dataset$Ozone>31 & dataset$Temp>90
dataset[dataset$Ozone>31 & dataset$Temp>90]
dataset[(dataset$Ozone>31 & dataset$Temp>90)==TRUE]
dataset[(dataset$Ozone>31 & dataset$Temp>90)==TRUE]
dataset[(dataset$Ozone>31 & dataset$Temp>90)==TRUE,]
subset<-dataset[(dataset$Ozone>31 & dataset$Temp>90)==TRUE,]
subset$Solar.R
subset[!is.na(subset$Solar.R)]
is.na(subset$Solar.R)
subset[!is.na(subset$Solar.R),]
subset[!is.na(subset$Solar.R),2]
mean(subset[!is.na(subset$Solar.R),2])
subset<-dataset[dataset$Month==6,]
subset$Temp
mean(subset$Temp)
max(dataset[dataset$Month==5,1])
dataset[dataset$Month==5,1]
dataset[dataset$Month==5,]
install.packages("swirl")
install.packages("curl")
setwd('/home/kushwanth/machinelearning/r_practice/DataScience_Specialization/R programming/assignment1')
electric_data = read.table("household_power_consumption.txt",sep=";",header=TRUE)
electric_data$Date_Time<-strptime(paste(electric_data$Date,electric_data$Time),"%d/%m/%Y %H:%M:%S")
electric_data[c(100,20000,50000),c(1,2,10)]
electric_data$Date <- as.Date(electric_data$Date, "%d/%m/%Y")
electric_data<-electric_data[electric_data$Date==as.Date("2007-02-01")|electric_data$Date==as.Date("2007-02-02"),]
#png("./plot3.png", width = 480, height = 480)
electric_data$Global_active_power<-as.numeric(electric_data$Global_active_power)
electric_data$Sub_metering_1<-as.numeric(electric_data$Sub_metering_1)
electric_data$Sub_metering_2<-as.numeric(electric_data$Sub_metering_2)
electric_data$Sub_metering_3<-as.numeric(electric_data$Sub_metering_3)
electric_data$Global_active_power<-as.numeric(electric_data$Global_active_power)
plot(electric_data$Date_Time,electric_data$Global_active_power,type='l',xlab='',ylab='Voltage',xlab='datetime',main='')
plot(electric_data$Date_Time,electric_data$Global_active_power,type='l',ylab='Voltage',xlab='datetime',main='')
plot(electric_data$Date_Time,electric_data$Voltage,type='l',ylab='Voltage',xlab='datetime',main='')
plot(electric_data$Date_Time,electric_data$Global_reactive_power,type='l',ylab='Global_reactive_power',xlab='datetime',main='')
